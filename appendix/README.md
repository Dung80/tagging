# Dataset

| Dataset | #Record | Quality | Task                      |
|---------|---------|---------|---------------------------|
| BIO     | 470K    | clean   | Multi-class classification|
| DEF     | 18K     | clean   | Multi-class classification|

# Model
- ALBERT (A Lite BERT)
- ROBERTA (A Robustly Optimized BERT Pretraining Approach)
- NB (Naive Bayes)
- XGBoost (A Scalable Tree Boosting System) 

# Metric
- Accuracy
- AUC (Area under the ROC Curve)

# Dependency
- pytorch 1.2.0
- pytorch-pretrained-bert 0.6.2
- scikit-learn 0.23.1
- transformers 2.3.0
- xgboost 1.1.0

# Reference 
**[Deep or Simple models for Semantic Tagging? It Depends on your Data](https://arxiv.org/abs/2007.05651)**
